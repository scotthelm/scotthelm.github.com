<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Postgres to CSV | Scott Helm</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Postgres to CSV" />
<meta name="author" content="Scott Helm" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Here lately, I have had to produce several reports from psql. If you’re anything like me, Then you’re all about automating automatable things. And you’re also probably all about simplicity. So I turned to my old friends, psql and cron. Overview If you want to automate something in Linux, figure out how to run it from the command line. Then run it from cron. You can automate cron from something like puppet or chef or docker The Command First of all - you will probably want to wrap a thing like this in a shell script. I use bash, so my ~/psql_report_script.sh would be like this: #!/bin/bash PGPASSWORD=$YOUR_ENVIRONMENT_VARIABLE psql -d &lt;database&gt; -h &lt;host&gt; -U &lt;username&gt; -c &#39;copy (select something from your_tables) TO STDOUT WITH CSV HEADER&#39; -o /path/to/your/file.csv Now chmod +x that file, and let’s break that command down just a little. PGPASSWORD=$YOUR_ENVIRONMENT_VARIABLE Now that&#39;s sensitive information. But it allows us to run the command without having to type the password in, and that&#39;s a good thing. That&#39;s why we use an environment variable. Pro tip - if you don&#39;t want a command to show up in history then put a space before it. psql That&#39;s our actual command -d that&#39;s the name of your database -h that&#39;s the hostname of your database server -U that&#39;s the database username -c that&#39;s the sql command to run. Since we want to output the contents of the query, we use the COPY command.[more on that here](http://www.postgresql.org/docs/current/static/sql-copy.html). This is pretty much the guts of the command. If your SQL is complicated, consider using the -f argument to pass in a file containing your sql command. In our COPY command we&#39;re telling psql to copy the result of the query to STDOUT and in a CSV format with headers -o that&#39;s where we want the file to be saved The Automation I like cron. It’s the easiest, fastest way to make things happen on a schedule on a linux machine. Here’s how to set it up. TLDR: type in crontab -e to edit your crontab file, and read the top line. From the how to set it up link: minute (0-59), hour (0-23, 0 = midnight), day (1-31), month (1-12), weekday (0-6, 0 = Sunday) The last part of the file is your command. So if I wanted this to run every day at 2am, my crontab line would look like this: 01 02 * * * /home/my_user/reports/psql_report_script.sh 30 02 * * * scp /path/to/your/file.csv some_user@mysftserver:/path/to/outfile.csv Here, I’m also exporting the file out to another server at 2:30am every morning. As you can see it’s not hard at all to set up a repeatable report extract using simple command-line tools." />
<meta property="og:description" content="Here lately, I have had to produce several reports from psql. If you’re anything like me, Then you’re all about automating automatable things. And you’re also probably all about simplicity. So I turned to my old friends, psql and cron. Overview If you want to automate something in Linux, figure out how to run it from the command line. Then run it from cron. You can automate cron from something like puppet or chef or docker The Command First of all - you will probably want to wrap a thing like this in a shell script. I use bash, so my ~/psql_report_script.sh would be like this: #!/bin/bash PGPASSWORD=$YOUR_ENVIRONMENT_VARIABLE psql -d &lt;database&gt; -h &lt;host&gt; -U &lt;username&gt; -c &#39;copy (select something from your_tables) TO STDOUT WITH CSV HEADER&#39; -o /path/to/your/file.csv Now chmod +x that file, and let’s break that command down just a little. PGPASSWORD=$YOUR_ENVIRONMENT_VARIABLE Now that&#39;s sensitive information. But it allows us to run the command without having to type the password in, and that&#39;s a good thing. That&#39;s why we use an environment variable. Pro tip - if you don&#39;t want a command to show up in history then put a space before it. psql That&#39;s our actual command -d that&#39;s the name of your database -h that&#39;s the hostname of your database server -U that&#39;s the database username -c that&#39;s the sql command to run. Since we want to output the contents of the query, we use the COPY command.[more on that here](http://www.postgresql.org/docs/current/static/sql-copy.html). This is pretty much the guts of the command. If your SQL is complicated, consider using the -f argument to pass in a file containing your sql command. In our COPY command we&#39;re telling psql to copy the result of the query to STDOUT and in a CSV format with headers -o that&#39;s where we want the file to be saved The Automation I like cron. It’s the easiest, fastest way to make things happen on a schedule on a linux machine. Here’s how to set it up. TLDR: type in crontab -e to edit your crontab file, and read the top line. From the how to set it up link: minute (0-59), hour (0-23, 0 = midnight), day (1-31), month (1-12), weekday (0-6, 0 = Sunday) The last part of the file is your command. So if I wanted this to run every day at 2am, my crontab line would look like this: 01 02 * * * /home/my_user/reports/psql_report_script.sh 30 02 * * * scp /path/to/your/file.csv some_user@mysftserver:/path/to/outfile.csv Here, I’m also exporting the file out to another server at 2:30am every morning. As you can see it’s not hard at all to set up a repeatable report extract using simple command-line tools." />
<link rel="canonical" href="/2014/07/24/postgresql-to-csv.html" />
<meta property="og:url" content="/2014/07/24/postgresql-to-csv.html" />
<meta property="og:site_name" content="Scott Helm" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2014-07-24T00:00:00-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Postgres to CSV" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Scott Helm"},"dateModified":"2014-07-24T00:00:00-04:00","datePublished":"2014-07-24T00:00:00-04:00","description":"Here lately, I have had to produce several reports from psql. If you’re anything like me, Then you’re all about automating automatable things. And you’re also probably all about simplicity. So I turned to my old friends, psql and cron. Overview If you want to automate something in Linux, figure out how to run it from the command line. Then run it from cron. You can automate cron from something like puppet or chef or docker The Command First of all - you will probably want to wrap a thing like this in a shell script. I use bash, so my ~/psql_report_script.sh would be like this: #!/bin/bash PGPASSWORD=$YOUR_ENVIRONMENT_VARIABLE psql -d &lt;database&gt; -h &lt;host&gt; -U &lt;username&gt; -c &#39;copy (select something from your_tables) TO STDOUT WITH CSV HEADER&#39; -o /path/to/your/file.csv Now chmod +x that file, and let’s break that command down just a little. PGPASSWORD=$YOUR_ENVIRONMENT_VARIABLE Now that&#39;s sensitive information. But it allows us to run the command without having to type the password in, and that&#39;s a good thing. That&#39;s why we use an environment variable. Pro tip - if you don&#39;t want a command to show up in history then put a space before it. psql That&#39;s our actual command -d that&#39;s the name of your database -h that&#39;s the hostname of your database server -U that&#39;s the database username -c that&#39;s the sql command to run. Since we want to output the contents of the query, we use the COPY command.[more on that here](http://www.postgresql.org/docs/current/static/sql-copy.html). This is pretty much the guts of the command. If your SQL is complicated, consider using the -f argument to pass in a file containing your sql command. In our COPY command we&#39;re telling psql to copy the result of the query to STDOUT and in a CSV format with headers -o that&#39;s where we want the file to be saved The Automation I like cron. It’s the easiest, fastest way to make things happen on a schedule on a linux machine. Here’s how to set it up. TLDR: type in crontab -e to edit your crontab file, and read the top line. From the how to set it up link: minute (0-59), hour (0-23, 0 = midnight), day (1-31), month (1-12), weekday (0-6, 0 = Sunday) The last part of the file is your command. So if I wanted this to run every day at 2am, my crontab line would look like this: 01 02 * * * /home/my_user/reports/psql_report_script.sh 30 02 * * * scp /path/to/your/file.csv some_user@mysftserver:/path/to/outfile.csv Here, I’m also exporting the file out to another server at 2:30am every morning. As you can see it’s not hard at all to set up a repeatable report extract using simple command-line tools.","headline":"Postgres to CSV","mainEntityOfPage":{"@type":"WebPage","@id":"/2014/07/24/postgresql-to-csv.html"},"url":"/2014/07/24/postgresql-to-csv.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="/rss.rss" title="Scott Helm" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest"></head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Scott Helm</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/all_posts.html">All Posts</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Postgres to CSV</h1>
    <p class="post-meta"><time class="dt-published" datetime="2014-07-24T00:00:00-04:00" itemprop="datePublished">
        2014-07-24
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Here lately, I have had to produce several reports from psql. If you’re anything
like me, Then you’re all about automating automatable things. And you’re also
probably all about simplicity. So I turned to my old friends, <code class="language-plaintext highlighter-rouge">psql</code> and <code class="language-plaintext highlighter-rouge">cron</code>.</p>

<h2 id="overview">Overview</h2>
<p>If you want to automate something in Linux, figure out how to run it from the
command line. Then run it from <code class="language-plaintext highlighter-rouge">cron</code>. You can automate <code class="language-plaintext highlighter-rouge">cron</code> from something like
<a href="http://puppetlabs.com">puppet</a> or
<a href="http://www.getchef.com/chef/">chef</a> or
<a href="http://www.docker.com">docker</a></p>

<h2 id="the-command">The Command</h2>
<p>First of all - you will probably want to wrap a thing like this in a shell
script. I use bash, so my <code class="language-plaintext highlighter-rouge">~/psql_report_script.sh</code> would be like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#!/bin/bash

 PGPASSWORD=$YOUR_ENVIRONMENT_VARIABLE psql -d &lt;database&gt; -h &lt;host&gt; -U &lt;username&gt; -c 'copy (select something from your_tables) TO STDOUT WITH CSV HEADER' -o /path/to/your/file.csv
</code></pre></div></div>

<p>Now chmod +x that file, and let’s break that command down just a little.</p>

<dl>
<dt>PGPASSWORD=$YOUR_ENVIRONMENT_VARIABLE</dt>
<dd>Now that's sensitive information. But it allows us to run the command without
having to type the password in, and that's a good thing. That's why we use an
environment variable. Pro tip - if you don't want a command to show up in <code>history</code> then put a space before it.</dd>

<dt>psql</dt>
<dd>That's our actual command</dd>

<dt>-d</dt>
<dd>that's the name of your database</dd>

<dt>-h</dt>
<dd>that's the hostname of your database server</dd>

<dt>-U</dt>
<dd>that's the database username</dd>

<dt>-c</dt>
<dd>that's the sql command to run. Since we want to output the contents of the
query, we use the <code>COPY</code> command.[more on that here](http://www.postgresql.org/docs/current/static/sql-copy.html). This is pretty much the guts of the 
command. If your SQL is complicated, consider using the -f argument to pass in
a file containing your sql command. In our COPY command we're telling psql to
copy the result of the query to STDOUT and in a CSV format with headers</dd>

<dt>-o</dt>
<dd>that's where we want the file to be saved</dd>
</dl>

<h2 id="the-automation">The Automation</h2>

<p>I like cron. It’s the easiest, fastest way to make things happen on a schedule
on a linux machine. Here’s <a href="https://help.ubuntu.com/community/CronHowto">how to set it up</a>. TLDR: type in <code class="language-plaintext highlighter-rouge">crontab -e</code> to edit your crontab file, and read the top
line. From the how to set it up link:</p>

<blockquote>
  <p>minute (0-59), hour (0-23, 0 = midnight), day (1-31), month (1-12), weekday (0-6, 0 = Sunday)</p>
</blockquote>

<p>The last part of the file is your command. So if I wanted this to run every day
at 2am, my crontab line would look like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>01 02 * * * /home/my_user/reports/psql_report_script.sh
30 02 * * * scp /path/to/your/file.csv some_user@mysftserver:/path/to/outfile.csv
</code></pre></div></div>

<p>Here, I’m also exporting the file out to another server at 2:30am every morning.</p>

<p>As you can see it’s not hard at all to set up a repeatable report extract using
simple command-line tools.</p>

  </div><div id="disqus_thread"></div>
  <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  var disqus_shortname = 'scotthelm'; // required: replace example with your forum shortname

  /* * * DON'T EDIT BELOW THIS LINE * * */
  (function () {
   var s = document.createElement('script'); s.async = true;
   s.type = 'text/javascript';
   s.src = '//' + disqus_shortname + '.disqus.com/count.js';
   (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
   }());
 </script>
  <!--
  <script>
    var disqus_config = function () {
      this.page.url = '/2014/07/24/postgresql-to-csv.html';
      this.page.identifier = '/2014/07/24/postgresql-to-csv.html';
    };

    (function() {
      var d = document, s = d.createElement('script');

      s.src = 'https://scotthelm.disqus.com/embed.js';

      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  -->
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript><a class="u-url" href="/2014/07/24/postgresql-to-csv.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/rss.rss">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">&copy; Scott Helm 2023</li>
          
        </ul>
      </div>
      <div class="footer-col">
        <p>Father, Husband, Technologist, Actor, Musician, Life-long Learner</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://github.com/scotthelm" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://linkedin.com/in/scott-helm-4a1aa52" target="_blank" title="linkedin">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#linkedin"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://stackoverflow.com/users/1518852/plasticide" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://twitter.com/scott_helm" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

</html>
